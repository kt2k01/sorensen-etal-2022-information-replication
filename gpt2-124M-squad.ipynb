{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eebca3b-1110-4a41-82b0-38878d00493f",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd62c22-9693-4956-90d6-6d66fb503443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as th\n",
    "import sys\n",
    "\n",
    "# suppress hugging face error\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bead4fb-d082-417a-bcad-7b57345575ac",
   "metadata": {},
   "source": [
    "### Load the model (GPT2, 124M parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9cc5ca2-50be-44bc-8eea-1a00b11006ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d3162-3e75-4239-9990-4b24e215684b",
   "metadata": {},
   "source": [
    "Show number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7533510-2fc0-4f1b-84a5-2c86f7148e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124439808"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab14dc9-1cf6-465b-833a-55906ff41b76",
   "metadata": {},
   "source": [
    "### Define the full token list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19299a1-abdc-4fa0-aeca-e958be076eb6",
   "metadata": {},
   "source": [
    "While the original paper uses their own token list, for SQUAD this should just be the full vocabulary supported by GPT-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fcafe08-a9b3-49ab-9a0b-e646e73ddd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [tokenizer.decode(i) for i in range(50257)]\n",
    "full_token_sets = set(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591ef96-8a58-4efb-9059-df39db1ea3c9",
   "metadata": {},
   "source": [
    "### Read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3743b6c6-0bde-44c1-86a9-da86cf6f863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train-v2.0.json\", \"r\") as f:\n",
    "    squad = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef5857-8c88-4bd9-b197-1d6c37421f39",
   "metadata": {},
   "source": [
    "Read in the full dataset and keep only the single word answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25028431-15d1-4607-a82b-454864b90b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9264 130319\n"
     ]
    }
   ],
   "source": [
    "# total number\n",
    "t = 0\n",
    "\n",
    "# single-word-answered questions\n",
    "single_questions = []\n",
    "\n",
    "for d in squad['data']:\n",
    "    for p in d['paragraphs']:\n",
    "        t += len(p['qas'])\n",
    "        for qa in p['qas']:\n",
    "            if not qa['is_impossible']:\n",
    "                for a in qa['answers']:\n",
    "                    if a['text'] in full_token_sets:\n",
    "                        single_questions.append({\"context\": p['context'], \"question\": qa['question'], \"answer\": a['text']})\n",
    "                        \n",
    "                        # only save one copy of the answer\n",
    "                        break\n",
    "    \n",
    "print(len(single_questions), t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebcebd8-02d1-4a7f-b77d-d606078b426e",
   "metadata": {},
   "source": [
    "### Define the entropy function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c6859-6a09-4b38-8459-843e723eb440",
   "metadata": {},
   "source": [
    "This definition is copied from original code. The scores from the GPT2 has to be softmaxed before using the entropy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39551581-280e-4504-8a2f-3ccea8bf8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(arr):\n",
    "    '''\n",
    "    Given an array of probabilities, calculate the entropy.\n",
    "    '''\n",
    "    return -sum(arr * np.exp(arr))\n",
    "\n",
    "softmax = nn.Softmax(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa857bcb-9e8f-4e63-ac6c-1181bfb466e0",
   "metadata": {},
   "source": [
    "### Define templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc38fc-d189-4fe8-bbbb-db185c5e32ba",
   "metadata": {},
   "source": [
    "The templates are copied from the original code. The entries with \"few-shot\" and \"SHOTS\" are currently removed. The answer has also been removed from the templates dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9786d229-4865-496c-9d89-96902583f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "\n",
    "            'instruction_qa0' : lambda row: (f\"TASK: Using words from the CONTEXT, answer the below QUESTIONS.\\n\\n\"\n",
    "            f\"CONTEXT:\\n{row['context']}\\n\\n\"\n",
    "            f\"QUESTIONS:\\n1) {row['question']}\\n\"\n",
    "            f\"Answer: \\\"\"),\n",
    "\n",
    "            'instruction_qa1' : lambda row: (f\"TASK: Answer the questions below using the phrasing from the context.\\n\\n\"\n",
    "            f\"CONTEXT:\\n{row['context']}\\n\\n\"\n",
    "            f\"QUESTIONS:\\n1) {row['question']}\\n\"\n",
    "            f\"Answer: \\\"\"),\n",
    "\n",
    "            'answer_key0' : lambda row: (f\"CHAPTER QUIZ\\n\\n\"\n",
    "            f\"PASSAGE:\\n{row['context']}\\n\\n\"\n",
    "            f\"QUESTIONS:\\n1) {row['question']}\\n\\n\"\n",
    "            f\"ANSWER KEY:\\n1)\"),\n",
    "\n",
    "            'answer_key1' : lambda row: (f\"ANSWER KEY:\\n\\n\"\n",
    "            f\"QUESTION1:\\n\\\"{row['context']}\\\" {row['question']}\\n\"\n",
    "            f\"ANSWER1:\"),\n",
    "\n",
    "            'dialogue0' : lambda row: (f\"P1: {row['context']}\\n\"\n",
    "            f\"P2: {row['question']}\\n\"\n",
    "            f\"P1: The answer is \\\"\"), \n",
    "\n",
    "            'dialogue1' : lambda row: (f\"P1 tells P2 some information, P2 asks comprehension questions, and P1 answers.\\n\\n\"\n",
    "            f\"P1: {row['context']}\\n\"\n",
    "            f\"P2: {row['question']}\\n\"\n",
    "            f\"P1: The answer is \\\"\"), \n",
    "\n",
    "            \"old0\": lambda row: (\"Context: \"f\"{row['context']}\" \"\\n\\nQ: \"f\"{row['question']}\"\"\\n\\nA:\"),\n",
    "\n",
    "            \"old1\": lambda row: (f\"{row['context']}\" \"\\n\\n\"f\"{row['question']}\\n\"\n",
    "            f\"The correct answer is:\"),\n",
    "        \n",
    "            \"old2\": lambda row: (\"I read this in a book today:\\n\"f\"{row['context']}\" \"\\n\"f\"{row['question']}\\nAnswer:\"),\n",
    "            \n",
    "            \"old3\": lambda row: (\"I read this in a book today:\\n\"f\"{row['context']}\" \"\\nFrom that context, did you catch \"f\"{row['question']}\\n\"\n",
    "            f\"Yes, the answer is\"),\n",
    "            \n",
    "            \"old4\": lambda row: (\"A friend of mine told me this:\\n\"f\"{row['context']}\\n\"\n",
    "            f\"My friend then asked: {row['question']}\\n\"\n",
    "            f\"I answered:\"),\n",
    "\n",
    "            \"openai0_shot\": lambda row: (\"Given the following passages and questions, provide a brief, correct answer from the text.\\n\"\n",
    "            f\"\\\"{row['context']}\\\", \\\"{row['question']}\\\" -> \\\"\"),\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f918039-34e5-461a-bddf-443b7846c481",
   "metadata": {},
   "source": [
    "### Run the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba491c9d-6f00-448d-a3ea-19625f166645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:00<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 9.00%, MI = -1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:59<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 8.00%, MI = -1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:57<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.00%, MI = -1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:45<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.00%, MI = -2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:45<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 10.00%, MI = -1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:57<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 16.00%, MI = -1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:35<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.00%, MI = -1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:38<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.00%, MI = -1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:41<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.00%, MI = -1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:46<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.00%, MI = -1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:44<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.00%, MI = -1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:44<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 4.00%, MI = -1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this version is working!\n",
    "\n",
    "N = 100\n",
    "\n",
    "accs = []\n",
    "mis = []\n",
    "\n",
    "for t in templates:\n",
    "    \n",
    "    all_entropy = []\n",
    "\n",
    "    # correct predictions\n",
    "    cor = 0\n",
    "\n",
    "    # flush for better formatting tqdm progress bar\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    for i in tqdm(range(N)):\n",
    "\n",
    "        input_text = templates[t](single_questions[i])\n",
    "\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "        gen_length = inputs['input_ids'].shape[1] + 1 # generate one new word\n",
    "\n",
    "        generation_output = model.generate(**inputs, \n",
    "                                           max_length=gen_length, return_dict_in_generate=True, output_scores=True,\n",
    "                                           pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "        idx = th.argmax(generation_output.scores[0])\n",
    "\n",
    "        if tokenizer.decode(idx) == single_questions[i]['answer']:\n",
    "            cor += 1\n",
    "\n",
    "        all_entropy.append(entropy(softmax(generation_output.scores[0][0])).item())\n",
    "        \n",
    "    acc = cor/N*100\n",
    "    accs.append(acc)\n",
    "    \n",
    "    mi = np.mean(all_entropy) # not mi, but off by a constant; also for squad, no collapse\n",
    "    mis.append(mi)\n",
    "    \n",
    "    print(f\"Accuracy = {acc:.2f}%, MI = {mi:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd48004-f755-49aa-80cf-14c557d459db",
   "metadata": {},
   "source": [
    "Plot the results. A weak correlation should be observed, because this is the smallest model. This part will be later updated with a KDE of correlation coefficient from different samples of N questions. My laptop currently does not support the second smallest GPT model in the paper (1.5B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da44644-52d5-437f-ad1b-00354972d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(mis, accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635c1e2-4a83-4978-a5c8-0c9ebac62bc8",
   "metadata": {},
   "source": [
    "The results are not visualized in the best way, but some interesting difference already emerge. This is perhaps mainly due to the small N and non-randomized sampling. Many accuracies are 0, while the MI's are extremely close (with one single exception)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff320708-8dfb-4fc4-b62e-58d5bf6ca7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
